"""
Checkpoint êµ¬ì¡° í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤í–‰: python debug_checkpoint.py
"""

import torch
from pathlib import Path

# checkpoint íŒŒì¼ ê²½ë¡œ
checkpoint_path = Path("unet_resnet50_best.pth")

if not checkpoint_path.exists():
    print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
    print("ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ë¡œ ì´ë™í•˜ì„¸ìš”.")
    exit(1)

print(f"ğŸ“ Checkpoint íŒŒì¼: {checkpoint_path}")
print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {checkpoint_path.stat().st_size / 1024 / 1024:.2f} MB\n")

# checkpoint ë¡œë“œ
print("â³ Checkpoint ë¡œë”© ì¤‘...")
checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

# checkpoint íƒ€ì… í™•ì¸
print(f"âœ… Checkpoint íƒ€ì…: {type(checkpoint)}\n")

if isinstance(checkpoint, dict):
    print("ğŸ“‹ Checkpoint Keys:")
    for key in checkpoint.keys():
        print(f"  - {key}")
    print()
    
    # state_dictê°€ ìˆëŠ” ê²½ìš°
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
        print("ğŸ“¦ state_dict Keys (ì²˜ìŒ 20ê°œ):")
    elif 'model' in checkpoint:
        state_dict = checkpoint['model']
        print("ğŸ“¦ model Keys (ì²˜ìŒ 20ê°œ):")
    else:
        # checkpoint ìì²´ê°€ state_dictì¸ ê²½ìš°
        state_dict = checkpoint
        print("ğŸ“¦ State Dict Keys (ì²˜ìŒ 20ê°œ):")
    
    # í‚¤ ëª©ë¡ ì¶œë ¥
    keys = list(state_dict.keys())
    for i, key in enumerate(keys[:20]):
        tensor = state_dict[key]
        print(f"  {i+1:2d}. {key:60s} â†’ shape: {list(tensor.shape)}")
    
    if len(keys) > 20:
        print(f"  ... (ì´ {len(keys)}ê°œ í‚¤)")
    
    print("\n" + "="*80)
    print("ğŸ” êµ¬ì¡° ë¶„ì„:")
    print("="*80)
    
    # í‚¤ íŒ¨í„´ ë¶„ì„
    patterns = {}
    for key in keys:
        prefix = key.split('.')[0] if '.' in key else key
        patterns[prefix] = patterns.get(prefix, 0) + 1
    
    print("\nì£¼ìš” ëª¨ë“ˆ (prefix):")
    for prefix, count in sorted(patterns.items(), key=lambda x: -x[1]):
        print(f"  - {prefix:20s}: {count:3d}ê°œ íŒŒë¼ë¯¸í„°")
    
    # ì¸ì½”ë” êµ¬ì¡° í™•ì¸
    print("\nì¸ì½”ë” êµ¬ì¡°:")
    encoder_keys = [k for k in keys if k.startswith('encoder')]
    if encoder_keys:
        print(f"  âœ… ë°œê²¬: {len(encoder_keys)}ê°œ ì¸ì½”ë” í‚¤")
        print(f"  ì˜ˆì‹œ: {encoder_keys[0]}")
    else:
        print("  âŒ 'encoder'ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ ì—†ìŒ")
    
    # ë””ì½”ë” êµ¬ì¡° í™•ì¸
    print("\në””ì½”ë” êµ¬ì¡°:")
    decoder_keys = [k for k in keys if 'decoder' in k.lower() or 'upconv' in k.lower()]
    if decoder_keys:
        print(f"  âœ… ë°œê²¬: {len(decoder_keys)}ê°œ ë””ì½”ë” í‚¤")
        print(f"  ì˜ˆì‹œ: {decoder_keys[0]}")
    else:
        print("  âŒ ë””ì½”ë” ê´€ë ¨ í‚¤ ì—†ìŒ")
    
    # Segmentation head í™•ì¸
    print("\nSegmentation Head:")
    seg_keys = [k for k in keys if 'seg' in k.lower()]
    if seg_keys:
        print(f"  âœ… ë°œê²¬: {len(seg_keys)}ê°œ segmentation í‚¤")
        print(f"  ì˜ˆì‹œ: {seg_keys[0]}")
    else:
        print("  âŒ segmentation ê´€ë ¨ í‚¤ ì—†ìŒ")
    
    # Classification head í™•ì¸
    print("\nClassification Head:")
    cls_keys = [k for k in keys if k.startswith('fc') or 'classifier' in k.lower()]
    if cls_keys:
        print(f"  âœ… ë°œê²¬: {len(cls_keys)}ê°œ classification í‚¤")
        for k in cls_keys:
            print(f"    - {k}: {list(state_dict[k].shape)}")
    else:
        print("  âŒ classification ê´€ë ¨ í‚¤ ì—†ìŒ")

else:
    print("âš ï¸ Checkpointê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤. ì§ì ‘ state_dictì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print(f"ì „ì²´ êµ¬ì¡°:\n{checkpoint}")

print("\n" + "="*80)
print("ğŸ’¡ ë¶„ì„ ì™„ë£Œ!")
print("="*80)
